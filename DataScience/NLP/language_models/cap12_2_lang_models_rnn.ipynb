{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Capítulo 12 - Redes Neurais Recorrentes\n",
    "\n",
    "## 12.2. Modelos de Linguagem Baseados em Redes Neurais Recorrentes\n",
    "\n",
    "O objetivo deste notebook consiste em desenvolver modelos de linguagem baseados em redes neurais recorrentes. Iremos abordar dois tipos de modelos:\n",
    "\n",
    "*   word-to-word: trata cada palavra do *corpus* como um documento. O processo de treinamento consiste em pares (palavra,próxima palavra) como sendo o texto e o rótulo;\n",
    "*   sentence-to-word: considera as palavras anteriores de uma sentença (e suas relações de dependência) do *corpus* para prever a próxima palavra.\n",
    "\n"
   ],
   "metadata": {
    "id": "qsStPDjrehxC",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding,Activation,Flatten,Dropout,Bidirectional\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical"
   ],
   "metadata": {
    "id": "-Kkjn6yWSVkn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'cap12_2_lang_models_rnn' from 'C:\\\\Users\\\\Guilherme\\\\Documents\\\\Programming\\\\Python\\\\Python_Projects\\\\DataScience\\\\NLP\\\\cap12_2_lang_models_rnn.py'>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import cap12_2_lang_models_rnn as myUtils\n",
    "importlib.reload(myUtils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "o2ixGd2AQEgL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'quero jogar futebol hoje\\n hoje não tem futebol\\n'"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"Quero jogar futebol hoje\\n Hoje não tem futebol\\n\"\n",
    "corpus = corpus.lower()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo de Linguagem do tipo Word-to-Word"
   ],
   "metadata": {
    "id": "3_SU9CMTf50C",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vocabulary = {}\n",
    "tokens = []\n",
    "for sentence in corpus.split('\\n'): # \"quero jogar futebol hoje\"\n",
    "    for word in sentence.split(): # # \"quero\"\n",
    "        tokens.append(word)\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word]+=1\n",
    "        else:\n",
    "            vocabulary[word]=1\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "print(\"vocabulary\", vocabulary, \"length:\",len(vocabulary))\n",
    "print(\"tokens\", tokens, \"length:\",len(tokens))"
   ],
   "metadata": {
    "id": "2s9NKeRvRujE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary {'quero': 1, 'jogar': 1, 'futebol': 2, 'hoje': 2, 'não': 1, 'tem': 1} length: 6\n",
      "tokens ['quero', 'jogar', 'futebol', 'hoje', 'hoje', 'não', 'tem', 'futebol'] length: 8\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(vocabulary)\n",
    "word2index = tokenizer.word_index\n",
    "word2index['<OOV>'] = 0\n",
    "word2index"
   ],
   "metadata": {
    "id": "-Lutla8-SIG7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "7d15d849-a35b-4f54-e379-6a956aee466b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "{'quero': 1,\n 'jogar': 2,\n 'futebol': 3,\n 'hoje': 4,\n 'não': 5,\n 'tem': 6,\n '<OOV>': 0}"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "index2word = {}\n",
    "for key in word2index: # \"quero\"\n",
    "    value = word2index[key] # \"1\"\n",
    "    index2word[value] = key # \"1\":\"quero\"\n",
    "\n",
    "index2word"
   ],
   "metadata": {
    "id": "um9s0lnETH5h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 'quero',\n 2: 'jogar',\n 3: 'futebol',\n 4: 'hoje',\n 5: 'não',\n 6: 'tem',\n 0: '<OOV>'}"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# tokens[0] = \"quero\"\n",
    "X_train = [0]\n",
    "y_train = [word2index[tokens[0]]] # [1]\n",
    "for i in range(0,len(tokens)-1): # 0 a 7\n",
    "    X_train.append(word2index[tokens[i]])\n",
    "    y_train.append(word2index[tokens[i+1]])\n",
    "X_train.append(word2index[tokens[len(tokens)-1]])\n",
    "y_train.append(0)"
   ],
   "metadata": {
    "id": "cDiK0PFUTlFm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary={'quero': 1, 'jogar': 1, 'futebol': 2, 'hoje': 2, 'não': 1, 'tem': 1}, len(vocabulary)=6\n",
      "tokens ['quero', 'jogar', 'futebol', 'hoje', 'hoje', 'não', 'tem', 'futebol'] length: 8\n",
      "word2index: {'quero': 1, 'jogar': 2, 'futebol': 3, 'hoje': 4, 'não': 5, 'tem': 6, '<OOV>': 0} length: 7\n",
      "corpus='quero jogar futebol hoje\\n hoje não tem futebol\\n'\n"
     ]
    }
   ],
   "source": [
    "print(f\"{vocabulary=}, {len(vocabulary)=}\")\n",
    "print(\"tokens\", tokens, \"length:\",len(tokens))\n",
    "print(\"word2index:\", word2index, \"length:\",len(word2index))\n",
    "print(f\"{corpus=}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l91d3K15U6Fz",
    "outputId": "58c1ec46-a67e-4578-c86f-9bf1cbc6b91f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 4, 5, 6, 3]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg1RD_1tU-js",
    "outputId": "10c04598-45cc-4089-c7c3-ba3fe383c00e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3, 4, 4, 5, 6, 3, 0]"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "# input_length=1 => word\n",
    "# input_dim=vocab_size => vocabulary size\n",
    "\n",
    "# TODO: why input_dim = vocab_size + 1? i think should be size 1\n",
    "model.add(Embedding(input_dim=vocab_size+1,output_dim=32,input_length=1))\n",
    "model.add(Bidirectional(LSTM(256,activation='relu')))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(vocab_size+1,activation='softmax'))"
   ],
   "metadata": {
    "id": "FO3__UIRVlrb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sgd = SGD(learning_rate = 0.001)\n",
    "model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=16,epochs=3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wKHw4qkWeW5",
    "outputId": "4d9d32c7-7f6c-4b4a-c01b-a798c1d74d4c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9456 - accuracy: 0.1111\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9474 - accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9458 - accuracy: 0.2222\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f898e6e370>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "frase = 'futebol quero jogar'\n",
    "\n",
    "for w in frase.split(): # \"futebol\"\n",
    "    idx = word2index[w] # 3\n",
    "    prob = model.predict([idx]) # [[0.14256176 0.14265485 0.14337164 0.14302562 0.14251715 0.14291811,  0.14295083]]\n",
    "    pal = np.argmax(prob) # [2] (indice da maior probabilidade)\n",
    "    print(f'Palavra atual: {index2word[idx]} Proxima palavra: {index2word[pal]}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxOXwZq6aXio",
    "outputId": "06757c9a-032b-4c74-d243-d2ca19b13f82",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 357ms/step\n",
      "Palavra atual: futebol Proxima palavra: não\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Palavra atual: quero Proxima palavra: <OOV>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Palavra atual: jogar Proxima palavra: tem\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo de Linguagem do tipo Sentence-2-Word\n",
    "\n",
    "Nesse tipo de modelo, as palavras são analisadas dentro das sentenças:"
   ],
   "metadata": {
    "id": "nTfcP50LdVMM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "novel_corpus = []\n",
    "y_train = []\n",
    "for sentence in corpus.split('\\n'): # \"quero jogar futebol hoje\"\n",
    "\n",
    "    novos_termos = sentence.split()\n",
    "\n",
    "    for i in range(0,len(novos_termos)): # 0 a 3\n",
    "        lista = novos_termos[:i+1]\n",
    "        novel_corpus.append(lista)\n",
    "        if i < len(novos_termos)-1: # i < 3\n",
    "            y_train.append(word2index[novos_termos[i+1]])\n",
    "        else:\n",
    "            y_train.append(0)"
   ],
   "metadata": {
    "id": "pqO1amVjdY-_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "novel_corpus"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTrActnGfEa7",
    "outputId": "6bcb2bd3-91dd-4918-d734-264f2defcd13",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[['quero'],\n ['quero', 'jogar'],\n ['quero', 'jogar', 'futebol'],\n ['quero', 'jogar', 'futebol', 'hoje'],\n ['hoje'],\n ['hoje', 'não'],\n ['hoje', 'não', 'tem'],\n ['hoje', 'não', 'tem', 'futebol']]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2NzTefBnncE",
    "outputId": "4ecb1d77-4b9c-4ef2-cffc-9f936aaa7cde",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3, 4, 0, 5, 6, 3, 0]"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_length = max([len(sentence) for sentence in novel_corpus])"
   ],
   "metadata": {
    "id": "_vwvNFvMjuZF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_length"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAEmLMVDkEzq",
    "outputId": "c2534177-85d2-4209-e6a5-78b05b881f98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(novel_corpus)"
   ],
   "metadata": {
    "id": "KMXwYWfrkIRI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_sequences"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfvcajYQkY4B",
    "outputId": "80c5607d-a0b4-4f88-a9eb-94e6d658f088",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "[[1], [1, 2], [1, 2, 3], [1, 2, 3, 4], [4], [4, 5], [4, 5], [4, 5, 3]]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trunc_type = 'post'\n",
    "padding_type = 'pre'\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ],
   "metadata": {
    "id": "HXv9j9u7kld8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "train_padded"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_eQgyb_kvMj",
    "outputId": "1aea3d9a-ee4a-4892-d853-34c4a7a81b6b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, 1],\n       [0, 0, 1, 2],\n       [0, 1, 2, 3],\n       [1, 2, 3, 4],\n       [0, 0, 0, 4],\n       [0, 0, 4, 5],\n       [0, 0, 4, 5],\n       [0, 4, 5, 3]])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=vocab_size+1,output_dim=32,input_length=max_length))\n",
    "model2.add(Bidirectional(LSTM(256,activation='relu')))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(vocab_size+1,activation='softmax'))"
   ],
   "metadata": {
    "id": "AEND9pGmk8bB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sgd = SGD(learning_rate = 0.001)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_padded,y_train,batch_size=16,epochs=3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4C5wFJIzlaYA",
    "outputId": "32399594-9994-4fc4-c11f-e2fcfd0a5745",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x000001F898DAF790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9466 - accuracy: 0.1250\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.9465 - accuracy: 0.2500\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9448 - accuracy: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f89985f370>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo de Linguagem com Corpus da Reuters\n",
    "\n",
    "**Homework:** desenvolver um modelo de linguagem do tipo Sentence-to-Word utilizando o vocabulário do *corpus* (split do treinamento) da reuters. Aproveite os splits de validação e de testes para experimentos.\n",
    "\n",
    "Obs.: delimitar o ```vocab_size``` para que seja possível a execução desse notebook no Google Colab. "
   ],
   "metadata": {
    "id": "9E-MMLp9bbCp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "vocab_size = 3000\n",
    "\n",
    "(x_train,y_train_int),(x_test2,y_test2) = reuters.load_data(num_words=vocab_size,test_split=0.3)\n",
    "word2index = reuters.get_word_index()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trppo9zHbf0Z",
    "outputId": "e5b9560b-5b87-4ce0-e559-79ca8cf6f187",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index2word = {}\n",
    "\n",
    "for key,value in word2index.items():\n",
    "  index2word[value] = key\n",
    "\n",
    "print(' '.join([index2word[x] for x in x_train[0]]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZEHU8eob4jQ",
    "outputId": "2576a73a-ec30-4115-ec5e-37f2fe3437d7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 115,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "8",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [115]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key,value \u001B[38;5;129;01min\u001B[39;00m word2index\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m      4\u001B[0m   index2word[value] \u001B[38;5;241m=\u001B[39m key\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([index2word[x] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m x_train[\u001B[38;5;241m0\u001B[39m]]))\n",
      "Input \u001B[1;32mIn [115]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key,value \u001B[38;5;129;01min\u001B[39;00m word2index\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m      4\u001B[0m   index2word[value] \u001B[38;5;241m=\u001B[39m key\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[43mindex2word\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m x_train[\u001B[38;5;241m0\u001B[39m]]))\n",
      "\u001B[1;31mKeyError\u001B[0m: 8"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lembre-se de construir as variáveis apropriadamente as variáveis ``` y_train ``` e ``` X_train ``` para treinamento dos modelos.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}